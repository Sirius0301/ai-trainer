{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f46acda4-5671-4378-8d51-27a654421e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_id customer_id   customer_name  order_date product_category  quantity  \\\n",
      "0   ORD001        C001     Alice Smith  2024-01-15      Electronics       2.0   \n",
      "1   ORD002        C002     Bob Johnson  2024-01-16         Clothing       3.0   \n",
      "2   ORD003        C003  Carol Williams  2024-01-17             Food       5.0   \n",
      "3   ORD004        C004     David Brown  2024-01-18      Electronics       1.0   \n",
      "4   ORD005        C005      Emma Davis  2024-01-19         Clothing       4.0   \n",
      "\n",
      "   unit_price  total_amount payment_method  customer_rating  discount_applied  \\\n",
      "0      899.99       1799.98    Credit Card              4.5              10.0   \n",
      "1       59.99        179.97         PayPal              4.0               5.0   \n",
      "2       12.99         64.95           Cash              3.5               0.0   \n",
      "3     1299.99       1299.99    Credit Card              5.0              15.0   \n",
      "4       39.99        159.96         PayPal              3.0               8.0   \n",
      "\n",
      "  shipping_city shipping_country  \n",
      "0      New York              USA  \n",
      "1   Los Angeles              USA  \n",
      "2       Chicago              USA  \n",
      "3       Houston              USA  \n",
      "4       Phoenix              USA  \n",
      "Original Rows: 451\n",
      "After Dropping NA Rows: 442\n",
      "After dropping duplicate rows: 271\n",
      "After converting the data: 271\n",
      "Remove outlier rows: 267\n",
      "After renaming columns: ['order_id', 'customer_id', 'customer_name', 'order_date', 'product_category', 'quantity', 'unit_price', 'revenue', 'payment_method', 'customer_rating', 'discount_applied', 'shipping_city', 'shipping_country']\n",
      "Final Rows: 86\n",
      "Deleted rows: 365 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('6_main_orders.csv')\n",
    "print(data.head())\n",
    "original_count = len(data)\n",
    "print(f\"Original Rows: {original_count}\")\n",
    "\n",
    "# 1. Drop Null\n",
    "data = data.dropna()\n",
    "print(f\"After Dropping NA Rows: {len(data)}\")\n",
    "\n",
    "# 2. Drop Duplicates\n",
    "data = data.drop_duplicates(subset='order_id')\n",
    "print(f\"After dropping duplicate rows: {len(data)}\")\n",
    "\n",
    "# 3. Convert Type + handling mistaken date: Convert `order_date` to datetime format\n",
    "data['order_date'] = pd.to_datetime(data['order_date'], errors='coerce')\n",
    "# drop converting failed rows\n",
    "data = data.dropna(subset=['order_date'])\n",
    "print(f\"After converting the data: {len(data)}\")\n",
    "\n",
    "# 4. Remove Outliers: Delete rows where `quantity` ≤ 0 or > 10, `unit_price` ≤ 0, or `customer_rating` < 1 or > 5\n",
    "data = data[\n",
    "    (data['quantity'] > 0) & \n",
    "    (data['quantity'] <= 10) & \n",
    "    (data['unit_price'] > 0) & \n",
    "    (data['customer_rating'].between(1, 5))\n",
    "]\n",
    "print(f\"Remove outlier rows: {len(data)}\")\n",
    "\n",
    "# 5. Rename Columns: Rename `total_amount` to `revenue`\n",
    "data.rename(columns={'total_amount': 'revenue'}, inplace=True)\n",
    "print(f\"After renaming columns: {data.columns.tolist()}\")\n",
    "\n",
    "# 6. Reorder Columns: Move `order_id`, `customer_id`, `order_date` to the front\n",
    "reorder_columns = ['order_id', 'customer_id', 'order_date']\n",
    "other_cols = [col for col in data.columns if col not in reorder_columns]\n",
    "data = data[reorder_columns + other_cols]\n",
    "\n",
    "# 7. Filter Rows: Keep only orders where `product_category` is \"Electronics\" AND `revenue` > 500\n",
    "data = data[\n",
    "    (data['product_category'] == 'Electronics') & \n",
    "    (data['revenue'] > 500)\n",
    "]\n",
    "\n",
    "# 8. Sort Data: Sort by `revenue` in descending order\n",
    "data = data.sort_values('revenue', ascending=False)\n",
    "\n",
    "# 9. Add New Columns: Add `is_high_value` column (True if revenue > 1000)\n",
    "data['is_high_value'] = data['revenue'] > 1000\n",
    "cleaned_count = len(data)\n",
    "\n",
    "# 10. Summary\n",
    "print(f\"Final Rows: {len(data)}\")\n",
    "print(f\"Deleted rows: {original_count - len(data)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "242d881f-155a-4901-8864-db1d2e9fcaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               order_id customer_id order_date customer_name product_category  \\\n",
      "0                ORD001        C001 2024-01-15   Alice Smith      Electronics   \n",
      "1                ORD101        C001 2024-04-25   Alice Smith      Electronics   \n",
      "2  ---DUPLICATED_ROW---        C001 2024-01-15   Alice Smith      Electronics   \n",
      "3                ORD022        C022 2024-02-05     Uma Lewis      Electronics   \n",
      "4                ORD004        C004 2024-01-18   David Brown      Electronics   \n",
      "\n",
      "   quantity  unit_price  revenue payment_method  customer_rating  ...  \\\n",
      "0       2.0      899.99  1799.98    Credit Card              4.5  ...   \n",
      "1       2.0      899.99  1799.98    Credit Card              4.5  ...   \n",
      "2       2.0      899.99  1799.98    Credit Card              4.5  ...   \n",
      "3       2.0      799.99  1599.98    Credit Card              4.5  ...   \n",
      "4       1.0     1299.99  1299.99    Credit Card              5.0  ...   \n",
      "\n",
      "   shipping_country is_high_value customer_name_cus                  email  \\\n",
      "0               USA          True       Alice Smith  alice.smith@email.com   \n",
      "1               USA          True       Alice Smith  alice.smith@email.com   \n",
      "2               USA          True       Alice Smith  alice.smith@email.com   \n",
      "3               USA          True        Victor Lee   victor.lee@email.com   \n",
      "4               USA          True       David Brown  david.brown@email.com   \n",
      "\n",
      "  age      city  country registration_date customer_tier lifetime_value  \n",
      "0  28  New York      USA        2023-01-10          Gold         8500.5  \n",
      "1  28  New York      USA        2023-01-10          Gold         8500.5  \n",
      "2  28  New York      USA        2023-01-10          Gold         8500.5  \n",
      "3  33   Detroit      USA        2023-05-15          Gold         9200.5  \n",
      "4  31   Houston      USA        2023-01-25          Gold         9200.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Original Rows: 451\n",
      "After Cleaning: 86\n",
      "Final Rows: 35\n"
     ]
    }
   ],
   "source": [
    "customer_data = pd.read_csv('6_customer_info.csv')\n",
    "customer_data = customer_data.dropna()\n",
    "customer_data = customer_data.drop_duplicates()\n",
    "# 11. Merge: Merge `main_orders.csv` and `customer_info.csv` on `customer_id`\n",
    "merged_data = pd.merge(data, customer_data, on='customer_id', how='inner', suffixes=('', '_cus'))\n",
    "print(merged_data.head())\n",
    "# 12. Filter: Keep only orders where `customer_tier` is \"Gold\" AND `age` is between 25-45\n",
    "merged_data = merged_data[(merged_data['customer_tier']=='Gold') & (merged_data['age'].between(25, 45))]\n",
    "# 13. Add Column: Add `profit_margin` column (assume cost is 70% of revenue)\n",
    "merged_data['profit_margin'] = merged_data['revenue'] * 0.3\n",
    "# 14. Group & Aggregate: Group by `customer_tier`, calculate average revenue, average age, and order count\n",
    "analysis = merged_data.groupby('customer_tier', observed=False).agg(\n",
    "    avg_revenue=('revenue', 'mean'),\n",
    "    avg_age=('age', 'mean'),\n",
    "    total_orders=('order_id', 'count')\n",
    "    ).reset_index()\n",
    "analysis = analysis.sort_values('avg_revenue', ascending=False)\n",
    "final = merged_data[['customer_name', 'age', 'customer_tier', 'revenue', 'profit_margin']].sort_values('revenue', ascending=False)\n",
    "final_count = len(final)\n",
    "final.to_csv('6_homework.csv', index=False)\n",
    "print(f\"Original Rows: {original_count}\")\n",
    "print(f\"After Cleaning: {cleaned_count}\")\n",
    "print(f\"Final Rows: {final_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
